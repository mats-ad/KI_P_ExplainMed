# ğŸ“„ ExplainMed â€“ KI-gestÃ¼tztes Diagnose-Dashboard mit XAI-ErklÃ¤rungen

ExplainMed ist ein Prototyp fÃ¼r ein KI-basiertes Diagnose-Dashboard, das medizinische Bilder klassifiziert und die Vorhersagen mithilfe von **Explainable AI (Grad-CAM, LIME, Occlusion Sensitivity)** visuell und textuell begrÃ¼ndet. Ziel ist es, Ã„rztinnen und Ã„rzten verstÃ¤ndliche KI-Ergebnisse bereitzustellen, um Vertrauen und Transparenz bei KI-gestÃ¼tzten Diagnosen zu erhÃ¶hen.

---

## ğŸš€ Features

- âœ… **Bild-Upload Ã¼ber Sidebar**
- âœ… **Klassifikation von Lungen- und Darmkrebs-Bildern**
- âœ… **3 XAI-Methoden:**

  - ğŸ”¥ Grad-CAM (hervorgehobene Bildregionen)
  - ğŸŸ¢ LIME (lokale Modell-Interpretierbarkeit)
  - ğŸŸ¥ Occlusion Sensitivity (SensitivitÃ¤tsanalyse durch Maskierung)

- âœ… **GPT-basierte Text-ErklÃ¤rung** (lokal Ã¼ber Ollama mÃ¶glich)
- âœ… **Download als PDF-Bericht**
- âœ… **Landing Page mit professionellem SaaS-Look und Preisstruktur**

---

## ğŸ“‚ Projektstruktur

```bash
KI_P_ExplainMed/
â”‚â”€â”€ app/
â”‚   â”œâ”€â”€ main.py                # Einstiegspunkt (Streamlit-App)
â”‚   â”œâ”€â”€ components.py          # Landing Page & Dashboard-Logik
â”‚   â”œâ”€â”€ xai_utils.py           # Grad-CAM, LIME, Occlusion
â”‚   â”œâ”€â”€ text_utils.py          # GPT-ErklÃ¤rungen & PDF-Generierung
â”‚   â”œâ”€â”€ pdf_utils.py           # PDF-Erstellung fÃ¼r Diagnoseberichte
â”‚   â””â”€â”€ models/                # EnthÃ¤lt trainiertes CNN-Modell (.pth)
â”‚
â”‚â”€â”€ assets/                    # Bilder und Beispiel-Screenshots
â”‚
â”‚â”€â”€ requirements.txt           # Alle benÃ¶tigten Python-Pakete
â”‚â”€â”€ README.md                  # Diese Datei
â”‚â”€â”€ config.toml                # Streamlit Theme-Konfiguration
â”‚â”€â”€ .gitignore                 # Git Ignore-Datei
```

### ğŸ” Wichtige Dateien

| Datei                       | Beschreibung                                                                   |
| --------------------------- | ------------------------------------------------------------------------------ |
| **app/main.py**             | Einstiegspunkt der App, enthÃ¤lt Navigation zwischen Landing Page und Dashboard |
| **app/components.py**       | EnthÃ¤lt Funktionen fÃ¼r Landing Page, Dashboard-Layout und Navigation           |
| **app/xai_utils.py**        | Methoden fÃ¼r Grad-CAM, LIME und Occlusion Sensitivity                          |
| **app/text_utils.py**       | EnthÃ¤lt die GPT-ErklÃ¤rungslogik (Ã¼ber Ollama oder Hugging Face)                |
| **app/pdf_utils.py**        | Generiert einen Diagnosebericht als PDF                                        |
| **config.toml**             | Theme-Einstellungen fÃ¼r Streamlit (Farben, Layout)                             |
| **models/resnet_model.pth** | Das trainierte CNN-Modell zur Klassifikation                                   |

---

## âš™ï¸ Installation

### 1ï¸âƒ£ Repository klonen

```bash
git clone https://github.com/mats-ad/KI_P_ExplainMed.git
cd KI_P_ExplainMed
```

### 2ï¸âƒ£ Virtuelle Umgebung erstellen und aktivieren

```bash
python3 -m venv ki_env
source ki_env/bin/activate   # Mac/Linux
ki_env\Scripts\activate      # Windows
```

### 3ï¸âƒ£ AbhÃ¤ngigkeiten installieren

```bash
pip install -r requirements.txt
```

---

## ğŸ§  Modell vorbereiten

ğŸ‘‰ Das CNN-Modell muss im Ordner `app/models/` liegen.
Der Dateiname sollte **`resnet_model.pth`** sein.

Falls du ein eigenes Modell trainieren willst, stelle sicher, dass du **ein ResNet-Modell mit angepasster `fc`-Schicht** trainierst.

---

## ğŸ–¥ï¸ App starten

```bash
streamlit run app/main.py
```

Dann im Browser Ã¶ffnen:
ğŸ‘‰ [http://localhost:8501](http://localhost:8501)

---

## ğŸ” Beispiel-Workflow

1. ğŸ“¤ Bild Ã¼ber die **Sidebar hochladen**
2. ğŸ“Š Dashboard zeigt:

   - Diagnose + Wahrscheinlichkeit
   - GPT-ErklÃ¤rung (oben links)
   - Grad-CAM, LIME, Occlusion (rechts/unten)

3. ğŸ“„ Diagnosebericht als PDF herunterladen

---

## ğŸ¤– GPT-ErklÃ¤rungen (lokal mit Ollama)

ğŸ”¹ Ollama installieren:
ğŸ‘‰ [https://ollama.ai/download](https://ollama.ai/download)

Dann in `text_utils.py` folgendes Modell nutzen:

```python
import ollama

def generate_textual_explanation(pred_class, gradcam_info, lime_info, occlusion_info):
    prompt = f"... Dein Prompt hier ..."
    response = ollama.chat(
        model="deepseek-r1:8b",
        messages=[{"role": "user", "content": prompt}]
    )
    return response["message"]["content"]
```

---

## ğŸ’° Preisstruktur (Business Plan Vorschlag)

| Plan           | Preis       | Features                                                   |
| -------------- | ----------- | ---------------------------------------------------------- |
| **Starter**    | 49â€¯â‚¬/Monat  | 100 Diagnosen, Basis-XAI, PDF-Reports                      |
| **Pro**        | 199â€¯â‚¬/Monat | Unbegrenzte Diagnosen, Erweiterte XAI, Teamzugang, Support |
| **Enterprise** | Auf Anfrage | API-Integration, On-Premise, Priorisierter Support         |
